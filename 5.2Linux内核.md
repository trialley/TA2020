ELF文件格式





堆和栈的区别？

- 申请方式不同。

  - 栈由系统自动分配。

  - 堆由程序员手动分配。

- 申请大小限制不同。

  - 栈顶和栈底是之前预设好的，大小固定，可以通过ulimit -a查看，由ulimit -s修改。

  - 堆向高地址扩展，是不连续的内存区域，大小可以灵活调整。

- 申请效率不同。

  - 栈由系统分配，速度快，不会有碎片。

  - 堆由程序员分配，速度慢，且会有碎片。









### 加载运行

- 克隆

  新程序的执行首先需要通过父进程外壳通过fork得到一个子进程，该子进程除了pid等标识和父进程不同外其他基本均与父进程相同。

- 重新映射

  当子进程执行execve系统调用时会先清空子进程现有的虚拟存储器段（简而言之就是不再映射到父进程的各个段），之后重新创建子进程虚拟存储器各段和可执行目标文件各段的映射。这个阶段我们可以理解为对复制来的父进程页表进程重写，映射到外存中可执行文件的各个段。



文件系统VFS的实现

新文件系统只要实现VFS的各个接口即可



VFS文件系统的基本结构是dentry结构体与inode结构体。是按照Ext的方式进行构建的，

super_block 超级块代表一个文件系统 定义在：<linux/fs.h>

>   存储一个已安装的文件系统的控制信息，代表一个已安装的文件系统；每次一个实际的文件系统被安装时，内核会从磁盘的特定位置读取一些控制信息来填充内存中的超级块对象。一个安装实例和一个超级块对象一一对应。超级块通过其结构中的一个域s_type记录它所属的文件系统类型。

```c++
/* 
 * 超级块结构中定义的字段非常多，
 * 这里只介绍一些重要的属性
 */
struct super_block {
    struct list_head    s_list;               /* 指向所有超级块的链表 */
    const struct super_operations    *s_op; /* 超级块方法 */
    struct dentry        *s_root;           /* 目录挂载点 */
    struct mutex        s_lock;            /* 超级块信号量 */
    int            s_count;                   /* 超级块引用计数 */
 
    struct list_head    s_inodes;           /* inode链表 */
    struct mtd_info        *s_mtd;            /* 存储磁盘信息 */
    fmode_t            s_mode;                /* 安装权限 */
};
 
/*
 * 其中的 s_op 中定义了超级块的操作方法
 * 这里只介绍一些相对重要的函数
 */
struct super_operations {
       struct inode *(*alloc_inode)(struct super_block *sb); /* 创建和初始化一个索引节点对象 */
    void (*destroy_inode)(struct inode *);                /* 释放给定的索引节点 */
 
       void (*dirty_inode) (struct inode *);                 /* VFS在索引节点被修改时会调用这个函数 */
    int (*write_inode) (struct inode *, int);             /* 将索引节点写入磁盘，wait表示写操作是否需要同步 */
    void (*drop_inode) (struct inode *);                  /* 最后一个指向索引节点的引用被删除后，VFS会调用这个函数 */
    void (*delete_inode) (struct inode *);                /* 从磁盘上删除指定的索引节点 */
    void (*put_super) (struct super_block *);             /* 卸载文件系统时由VFS调用，用来释放超级块 */
    void (*write_super) (struct super_block *);           /* 用给定的超级块更新磁盘上的超级块 */
    int (*sync_fs)(struct super_block *sb, int wait);     /* 使文件系统中的数据与磁盘上的数据同步 */
    int (*statfs) (struct dentry *, struct kstatfs *);    /* VFS调用该函数获取文件系统状态 */
    int (*remount_fs) (struct super_block *, int *, char *); /* 指定新的安装选项重新安装文件系统时，VFS会调用该函数 */
    void (*clear_inode) (struct inode *);                 /* VFS调用该函数释放索引节点，并清空包含相关数据的所有页面 */
    void (*umount_begin) (struct super_block *);          /* VFS调用该函数中断安装操作 */
};
```

Inode 代表一个文件  定义在：<linux/fs.h>

> 索引节点对象存储了文件的相关信息，**代表了存储设备上的一个实际的物理文件**。当一个文件首次被访问时，内核会在内存中组装相应的索引节点对象，以便向内核提供对一个文件进行操作时所必需的全部信息；这些信息一部分存储在磁盘特定位置，另外一部分是在加载时动态填充的。



Dentry代表一个文件目录中的一个点，可以是目录也可以是文件。



一个inode可能会对应多个dentry项。（hard link）

在挂载的过程中，最为重要的数据结构是vfsmount，它代表一个挂载点。其次是dentry和inode，这两个都是对文件的表示，且都会缓存在哈希表中以提高查找的效率。其中inode是对磁盘上文件的唯一表示，其中包含文件的元数据（管理数据）和文件数据等内容，但不含文件名称。而dentry则是为了Linux内核中查找文件方便虚拟出来的一个数据结构，其中包含文件名称、子目录（如果存在的话）和关联的inode等信息。





d_name代表一个路径节点的名称（文件夹名称）、d_hash则用于构建哈希表，d_subdirs则是下级目录（或文件）的列表。这样，通过dentry就可以形成一个非常复杂的目录树。



inode这里面主要涉及3个结构体，分别是address_space、inode_operations和file_operations，其中每一个结构体中都包含很多函数指针。

一个打开的文件必须隶属于某个进程



在Linux操作系统中，文件的打开必须要与进程（或者线程）关联，也就是说一个打开的文件必须隶属于某个进程。在linux内核当中一个进程通过task_struct结构体描述，而打开的文件则用file结构体描述，打开文件的过程也就是对file结构体的初始化的过程。在打开文件的过程中会将inode部分关键信息填充到file中，特别是文件操作的函数指针。在task_struct中保存着一个file类型的数组，而用户态的文件描述符其实就是数组的下标。这样通过文件描述符就可以很容易到找到file，然后通过其中的函数指针访问数据。







### 进程管理

1. 进程、线程、协成的统一辨析
   1. 概念区别
   2. 操作系统为什么有用户态和内核态，用户级线程与内核级线程如何转换
   3. 实现区别
      1. 内存分布
      2. 协程切换方式
         1. ？？？ glibc ucontext
         2. protothreads  使用“Duff's Device” 全局变量
         3. libco libgo 直接切换上下文，自己管理栈
         4. ？？？ setjmp与longjmp
2. 进程生命周期与条件![img](https://ss0.bdstatic.com/70cFvHSh_Q1YnxGkpoWK1HF6hhy/it/u=2009938282,2324889060&fm=26&gp=0.jpg)
3. 进程调度策略
   1. 原则
   2. 算法
      1. 分片机制
      2. Linux进程是如何调度的
         1. 采用红黑树作为调度的数据结构、
         2. 
   3. 多处理器调度
5. 多线程模型
6. 进程同步
   1. 临界区问题
   2. 解决方案
   3. 信号量应用
   4. 管程应用
7. 死锁
   1. 死锁的四个必要条件
   2. 死锁预防
   3. 死锁避免
   4. 死锁检测
   5. 死锁恢复





### 进程间通信



Linux信号、管道等的实现

### 内存管理



1. 分段、分页、虚拟内存是什么？其在intel中实现是什么？
2. 内存分区
3. 虚拟内存
   1. 按需调页
   2. 写时复制
   3. 页面置换
   4. 帧分配
   5. 抖动
   6. 内存映射文件
4. linux的内存管理机制
5. linux内存布局
   内核空间
   栈区
   映射区
   堆区
   未初始化数据
   已初始化数据
   data代码段



虚拟内存的意义和工作过程、，问的很多，但都很基础

堆和栈、内存分区、虚拟内存 + 物理内存





### 文件系统

磁盘组织方式

分区格式

目录的实现



文件存储方式

空闲空间管理方式





Linux文件系统组成

inode和数据存放的位置

Linux各个文件夹的作用





###  大容量存储器

##### 磁盘结构

盘面+柱面>磁道>扇区>物理相邻的若干个扇区称为一个簇。簇越大存储性能越好，但空间浪费严重。簇越小性能相对越低，但空间利用率高。

SMR叠瓦式硬盘：![【第十期】为啥叠瓦式硬盘被用户吐槽？ - 知乎](D:\Users\12037\Desktop\【第十期】为啥叠瓦式硬盘被用户吐槽？ - 知乎.jpg)

##### 磁盘调度算法

1. FCFS先来先服务
   1. 公平
   2. 效率低
2. SSTF最短寻道时间优先
   1. 性能高但不是最优
   2. 会饥饿
3. SCAN电梯调度算法
   1. 浪费一端时间
   2. 避免饥饿
4. C-SCAN单向移动的电梯调度算法（比较好
   1. 等待时间均匀，比scan更公平
5. LOOK移动到最远点
   1. 提高了效率
6. C-LOOK
   1. 提高了效率

##### RAID 独立磁盘冗余技术Redundant Array of Independent Disks 

- 镜像-通过冗余改善可靠性
- 分散-通过并行改善性能
  - 位级分散
  - 块级分散

1. RAID0 无冗余磁盘阵列  块级分散 不容错 
2. RAID1 磁盘镜像
3. RAID2 位级分散差错纠正
4. RAID3 位交织奇偶
5. RAID4 块交织奇偶
6. RAID5是最常见的奇偶校验RAID 系 统 
7. RAID6 P+Q冗余方案
8. 





### IO与网络系统



- 同步  数据搬迁等待
  - 阻塞  暂停等待响应
  - 非阻塞 不暂停
- 异步 数据搬迁不等待

常考的五种IO模型

1. 阻塞IO：搬迁数据；等待数据均卡住
2. 非阻塞IO：等待数据时轮询；搬迁数据时卡住
3. 信号驱动IO：数据等待不轮询，而是使用信号；数据搬迁卡主
4. IO多路复用：同时对多个阻塞；数据搬移卡主
5. 异步IO：数据等待与搬迁均交给内核完成，

|    名字    | 数据等待过程 | 数据搬迁过程 |
| :--------: | ------------ | ------------ |
|   阻塞UI   | 等           | 等           |
|  非阻塞IO  | 轮询         | 等           |
| 信号驱动IO | 注册信号处理 | 等           |
| IO多路复用 | 等多个       | 等           |
|   异步IO   |              | 注册信号处理 |



![img](https://img-my.csdn.net/uploads/201007/31/0_1280551552NVgW.gif)







缓冲区buffer与高速缓存cache

- 缓冲区：保存数据
- 高速缓存：加速数据传输



假脱机spooling：通过模拟硬件实现并发访问![SPOOLing技巧(D:\Users\12037\Desktop\寒假春招知识点整理\基础知识\操作系统.assets\SPOOLing技巧(假脱机技巧)_weixin_33712987的博客-CSDN博客-1581759635101.jpg)_weixin_33712987的博客-CSDN博客](D:\Users\12037\Desktop\SPOOLing技巧(假脱机技巧)_weixin_33712987的博客-CSDN博客.jpg)

1. 控制程序
2. 进程
3. 缓冲区
4. 井



同步和异步：函数执行，数据在内核与程序间复制的过程

阻塞与非阻塞：调用函数，等待复制机会的过程

Reactor是同步非阻塞 事件驱动模型

Proactor异步非阻塞

epoll的原理



### 虚拟化

docker的cgroup机制和namespace机制的实现





### 书籍大总结

1. √《Linux内核设计与实现》强烈推荐！！！全书
   1. 可以理解为《深入理解Linux内核》的精简版
   2. 讲解了linux设计的一些思想
2. √《深入理解Linux内核》重点阅读内存管理和进程调度章节
   1. linux的实现细节
3. √《Unix高级环境编程》全书
   1. 讲解了unix函数规范与一些变量取值的使用惯例，讲了各种别名之类差不多是一本字典
4. √《深入理解计算机系统》除了汇编部分，其余章节都看了
   1. 从0-1的计算机入门书籍









1. UNP重点有三个部分。


   - 各个socket API的对应到OS，做了哪些事情，比如connect后，做了哪些事情?，accept呢?，什么是RST报文?，什么是SIGPIPE，如何触发的?
   - 网络IO模型，同步和异步，阻塞和非阻塞的概念，Linux上各种网络IO模型的优缺点对比，epoll、select、信号驱动IO等
   - 服务器的网络编程模型，多线程、多进程、线程池等，各自优缺点
   - 
   - 
   - 
   - 
   - 
   - 如何排查Load高的问题

1. iptables的四表五链

   1. 四表就是四种对包的过滤与修改规则
   2. 五链就是对包的五个检查点
      1. 进入内核前
      2. 进入程序前
         3. 内核直接转发中
      3. 程序到内核时
         5. 内核发出时
2. Nginx的网络IO模型(这个很重要，你要能讲清楚为什么Nginx要比Apache好)
3. select
4. poll
5. epoll
   1. ET与LT的使用情形
6. C10K 问题
7. 分布式系统CAP原则又称CAP定理，指的是在一个分布式系统中，一致性（Consistency）、可用性（Availability）、分区容错性（Partition tolerance）。CAP 原则指的是，这三个要素最多只能同时实现两点，不可能三者兼顾。
   1. 一致性（Consistency）在分布式系统中的所有数据备份，在同一时刻是否同样的值。同于所有节点访问同一份最新的数据副本
   2. 可用性（Availability）集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求。
   3. 分区容错性（Partition tolerance）分布式系统中有某一个或者几个机器宕掉了，其他剩下的机器还能够正常运转满足系统需求
   4. 为什么CAP只能同时实现两个？
      1. 



并发量有多少？

开了多少连接？想要支持更多连接怎么办？最大能设置为多大？（我猜应该是想考：ulimit -n）

epoll原理实现，为什么用红黑树，好处，时间复杂度，具体插入过程？

C++11有哪些特性？

智能指针是线程安全的吗？哪些地方需要考虑线程安全？

如何访问非法栈空间？

共享内存了解吗？最大有多大？能不能超过物理内存？硬盘大小呢？

协程了解吗，有什么作用？怎么实现的？上下文切换保存什么内容？

分布式系统了不了解？

看直播吗？看什么直播？虎牙斗鱼直播有区别吗？

还有什么问题？



2. ***CAP*原则_百度百科](http://www.baidu.com/link?url=ep7-4mT5D7IHRgrDbnbK5gdB2OuiANs6PQ-Mn_Wwokzabx2MJA7v_mTATjr7HzHFVk22PNfzuxgSha2uIRwivfZUstCBW6-1vndBYgTHGYe)**

3. **Linux 网络编程：**

   1、Linux 进程环境：僵尸进程、孤儿进程、守护进程、进程组、会话、前台进程组、后台进程组

   2、Linux 进程七大通信方式：signal、file、pipe、shm、sem、msg、socket

   3、Linux 线程：互斥量、锁机制、条件变量、信号量、读写锁

   4、Linux 下并发模型：多进程、多线程、线程池

   5、Linux 下 I/O 复用：select、poll、epoll 高并发

   6、Linux 网络编程

   7、静态库和动态库

4. IO复用、epoll

5. 讲下怎么思考分布式的东西，说下学到什么程度了，都详细讲讲。有没有什么实践的？？
   多少种RPC框架？都讲下。虚拟机学到多深了？？讲下？

6. Nginx的网络IO模型(这个很重要，你要能讲清楚为什么Nginx要比Apache好)

7. iptables的三表五链

8. 看你做过linux服务器的开发 那么说说epoll

9. epoll的触发方式 水平触发和边沿触发说一说

10. 1. 

11. 11.  多线程是解决什么问题的？线程池解决什么问题？


   8- 搭建高并发高可用系统需要怎样设计？考虑哪些东西，有多少说多少。

4. **分布式架构与应用设计等等**

   1. 常用负载均衡策略

   2. 一致性hash原理

   3. 缓存容灾中数据一致性问题

   4. 了解cap理论吗

   5. 介绍下高可用，高性能，可伸缩基本概念。。

   6. 了解微服务？docker？k8s?

   7. Nginx了解到什么程度，nginx配置更新实现，事件模型

   8. 给一个场景，设计一下定时对url进行爬虫，比如对新浪1个小时爬虫n次，然后某些博客可能1个星期爬虫1次。

   9. 给一个场景，设计服务器实现爬虫的url去重，如何让多个服务器对一个url爬虫指定次数

   10. 好多小文件，设计一个服务器来实现如何存储

   11. 设计两地高效传文件

   12. 场景题：5000人同时执行转账，编写线程时要注意什么？没学过数据库没关系，可以认为数据在内存中（穿插着问了死锁）

   13. 场景题：抖音有十亿用户，32字节的userid和double类型的活跃度数据，保存在1000个文件中每个文件100万行。找出这些文件中活跃度最高的10000个玩家的userid和活跃度的数值（穿插着问了堆的实现）

   14. 作者：特立独行MVP
       链接：https://www.nowcoder.com/discuss/188367
       来源：牛客网

   15. 

       

       ## 云计算

       为什么会接触到云计算其实也是之前实习的时候重要做的项目，主要就是关于docker容器化以及Kubernetes容器编排框架。
       docker在容器化的贡献是巨大的，也可以为我们在日常配置服务过程当中减去非常大的麻烦，不论是工作中还是平时自己的使用都是非常友好的。
       如果是走这个方向的话对于docker以及k8s是必修的，建议看看下面的书或者博客：

       - Kubernetes权威指南 
       - docker源码剖析 
       - 极客时间：深入剖析Kubernetes专栏



## 网络编程

- 接收数据

  `// 返回接收到的数据的字节数，没有可用数据或对方已经断开连接时返回0。失败时返回 -1。(TCP)``ssize_t recv(``int` `sockfd, ``void` `*buf, size_t nbytes, ``int` `flags);` `// 通常用于无连接的套接字(UDP)。``ssize_t recvfrom(``int` `sockfd, ``void` `*buf, size_t len, ``int` `flags,``         ``struct sockaddr *src_addr, socklen_t *addrlen);`

- 发送数据

  `// 成功时返回发送的字节数，注意这只是表示数据被写到了缓冲区，而不是发送到了目的地。错误时返回-1。(TCP)``int` `send(``int` `sockfd, ``const` `void` `*buf, size_t nbytes, ``int` `flags);` `// 用于对无连接的套接字发送数据(UDP)``ssize_t sendto(``int` `sockfd, ``const` `void` `*buf, size_t len, ``int` `flags,``        ``const` `struct sockaddr *dest_addr, socklen_t addrlen);`

### IO模型

同步IO和异步IO的区别在于进行IO时进程是否阻塞/是否能执行其他命令.
阻塞IO和非阻塞IO的区别在于当IO未就绪时是否等待, 阻塞/非阻塞IO都属于同步IO.

1. 同步IO

   - 阻塞式I/O: 当读写操作不能开始时, 进程会被阻塞. 当读写操作完成时才会返回.
   - 非阻塞式I/O: 当请求的IO操作需要阻塞进程时, 不阻塞进程, 而是返回一个错误.
     以后进程可以不断发起读写请求.
   - I/O复用: 同时等待多个文件描述符.
   - 信号驱动式I/O: 首先进程注册一个信号处理函数, 随后当IO就绪时, 操作系统会发送SIGIO信号,
     通知进程**可以进行IO**. 此时进程的信号处理程序被调用, 进程可以在信号处理程序中进行IO,
     也可以通知主程序来进行IO.

2. 异步I/O

   异步IO函数的机制是: 告知内核启动某个操作, 并让内核在整个**操作完成**后通知自己.
   信号驱动是可以进行IO时通知进程, 异步IO是IO操作完成后通知进程.

### IO复用接口

#### select

等待多个文件描述符, 当任意一个可用时, select 就返回, 否则一直阻塞. 函数返回时, 如果不是因为超时,
可以通过遍历文件描述符来找到就绪的描述符(用 FD_ISSET 检测文件描述符).

select 对等待的文件描述符数量有限制.

函数参数为: 三个集合大小中的最大值加一, 等待读的文件描述符集合, 等待写的文件描述符集合,
等待异常的文件描述符集合, 最长等待时间. 返回值是就绪的文件描述符数量.

#### poll

同样是等待多个文件描述符, 当一个就绪或超时时就返回, 需要遍历 fd 来获得就绪的 fd.

poll没有等待的数量的限制, 但是过多时性能会下降.

通过pollfd集合来指定文件描述符.

#### epoll

首先建立一个epoll句柄, 内核此时会建立一个数据结构来维护要等待的文件描述符及其事件.

然后通过epoll_ctl增删改等待的文件描述符及其事件.

最后通过epoll_wait来等待文件描述符就绪.

epoll有两种工作模式: 水平触发(level trigger)和边沿触发(edge trigger).
水平触发是默认的工作模式, 指当IO就绪时, epoll_wait 检测到事件后, 如果不处理, 事件不会立刻销毁,
下次调用 epoll_wait 时仍然可以检测到此事件.
边沿触发则不同, 当 epoll_wait 检测到事件后, 就会将事件销毁, 如果不处理, 下次 epoll_wait 就不能检测到此事件.

因此当采用边沿触发时, 如果读到的数据与请求的大小相同, 很可能还有数据没有读完. 因此此时要采用非阻塞读,
直到返回的数据少于请求的数据或返回EAGAIN错误.

epoll_wait 可以直接得到就绪的文件描述符以及对应的事件, 因此不需要扫描所有文件描述符.

epoll 相比 poll 和 select 的另一个优势是不需要在每次调用时都将文件描述符集合复制到内核空间.

epoll 的最大 fd 数等于最大的可打开文件数.

#### IO复用的实现原理

IO设备的驱动程序中有一个等待队列, 可以通过驱动程序提供的 poll 接口来获取IO设备是否就绪, 也可以将进程加入到等待对应的等待队列中.
当IO设备就绪时, 就可以通知等待队列中的进程, 将其从睡眠中唤醒.
select, poll 的实现是:

1. 扫描所有 fd, 利用 poll 接口检测对应的IO是否就绪, 并将进程加入到等待队列.
2. 如果存在就绪的 fd, 就在遍历后返回就绪 fd 的数量.
3. 如果没有就绪的 fd, 就睡眠一段时间.
4. 如果休眠结束或被IO驱动程序唤醒, 继续循环上面的过程. 如果是后者, 就会检测到就绪的 fd, 从而可以在第二步返回.

epoll 流程也类似上面, 只有下面几点不同:

- epoll 在创建句柄时将 fd 集合拷贝到内核, epoll_wait 时不需要再拷贝 fd 集合, 这样对同一集合多次调用 epoll_wait 时就只需要拷贝一次.
- epoll 的句柄通过一个红黑树来维护 fd 集合, 每次加入时会先在红黑树中查找是否已经保存了该 fd,
  时间复杂度是 log(N)*l**o**g*(*N*).
- epoll 第一次也要遍历 fd, 并将进程加入到等待队列, 但是同时为每个 fd 指定了回调函数, 当 fd 就绪时,
  设备驱动程序会唤醒进程, 并调用此回调函数. 这个回调函数的作用是将这个就绪的 fd 加入到就绪链表.
  因此, 当进程从等待中被唤醒时, 就可以直接通过检查这个就绪链表是否为空来判断是否有 fd 就绪,
  而不需要像 select/poll 一样再次遍历 fd 集合.
- 调用 epoll_wait 时, 会把就绪的 fd 拷贝到用户态内存, 然后清空就绪链表, 最后再检查这些 fd.
  在水平触发模式下, 如果检查到这些 fd 上还有未处理的事件, 会将这些 fd 放回就绪链表中, 保证事件得到正确处理.
- 对于 fd 集合大小的限制, epoll 是进程可以打开的最大文件数目, 这个值保存在 /proc/sys/fs/file-max.

参考
[select()/poll() 的内核实现](http://janfan.cn/chinese/2015/01/05/select-poll-impl-inside-the-kernel.html),
[select，poll，epoll实现分析—结合内核源代码](https://www.linuxidc.com/Linux/2012-05/59873.htm).

#### select, poll, epoll的应用场景

并不是说 epoll 一定要比 select 和 poll 要好, 例如由于 epoll 在设备驱动程序注册的回调函数,
每次对应的 fd 就绪时, 都会在内核空间因此一次额外的函数调用, 将对应 fd 插入到就绪集合中.
当大都是短连接, 或大都是发送少量数据时, 带来的开销可能比可能可能比 poll 更大.

### socket读写

socket 函数用于创建套接字(socket), bind 函数可以将套接字绑定到本地的一个地址(ip:port),
不为socket指定地址时, 在对socket调用 connect 或 listen 时, 内核会自动为socket选择一个地址.

客户端建立连接是的函数调用过程: socket(), bind()(可省略), connect(), send()/write().

服务端处理连接的函数调用过程: socket(), bind(), listen(), accept(), recv()/read().

- TCP通信

  connect 函数用于向指定地址发起连接(客户端), listen 函数用于向内核声明scoket可以接受连接(服务端),
  用 accept 函数即可获取连接.

  当调用 connect 函数时, 客户端发出 SYN 数据包. 服务端如果已经调用了 listen, 就会对此回复 ACK+SYN,
  connect 函数接收到此回复后, 再回复 ACK, connect 函数即可返回. 此时一个连接就已经建立.

  随后服务端可以调用 accept 函数, 获取对应的文件描述符, 调用 read 函数和 write 函数来读写数据,
  二者都是返回已经读/写的比特数. 注意 write 函数返回时只是将数据写到了内核缓冲区, 并不能保证已经发送出去了.

  recv 函数和 send 函数专门用于向套接字读/写数据, 但是相比 read 和 write, 提供了额外的一个参数,
  当参数为0时等价.

  close 函数将会把一个套接字标记为关闭, 并立即返回. 之后调用者不能再向该套接字读写数据.
  但是此时缓冲区中可能还有数据, 内核将会将排队等待的数据发送到对端, 发送完毕之后才会执行的TCP连接关闭操作.

  调用 close 函数后, 对端的读操作将会返回一个 EOF.

  套接字描述符同文件描述符一样, 也维护了引用计数, 只有当引用计数为0时, 才会真正执行TCP挥手过程.

  int shutdown(int sockfd, int howto) 函数则会直接关闭套接字描述符, 不管其引用计数有多少.
  并且 howto 参数可以控制是关闭连接的读, 写, 读+写.

- UDP通信

  UDP通信不需要建立连接, 可以直接向指定地址读/写数据, 函数是:

  `ssize_t recvfrom(``int` `sockfd, ``void` `*buf, ``size_t` `len, ``int` `flags,``        ``struct` `sockaddr *src_addr, socklen_t *addrlen);``ssize_t sendto(``int` `sockfd, ``const` `void` `*buf, ``size_t` `len, ``int` `flags,``      ``const` `struct` `sockaddr *dest_addr, socklen_t addrlen);`

  对于 sendto 函数, 如果已经对sockfd调用 connect 建立了连接(是的, 即使是UDP也可以调用 connect),
  dest_addr参数和addrlen参数会被忽略.

  对于 recvfrom 函数, src_addr参数用于保存数据发送者的地址, addrlen参数说明了地址参数的长度.

  UDP通信的过程一般是:

  客户端和服务端都用 socket 函数创建套接字, 其中服务端还要用 bind 函数将套接字绑定到一个地址.
  客户端调用 sendto 函数向指定地址发送数据, 数据写到缓冲区时 sendto 函数返回.
  服务端用 recvfrom 函数接收数据, 返回读取到的字节数.
  此时一次数据发送就完成了. 服务端可以再用 sendto 函数回复数据, 客户端用 recvfrom 函数接收数据.

一个数据包是如何被接收的呢? 下面描述一下操作系统接收数据包的过程:

1. 数据包到达, 产生中断.
2. 检测设备.
3. 接收链路层包头.
4. 为数据包分配空间.
5. 通知总线将数据包放到缓存.
6. 将数据包放到 backlog 队列(累积队列).
7. 设置标志以运行"网络调度器".
8. 返回到进程.

TCP接收一个数据包的过程为:

1. 检测seq和标志, 如果合法就将数据包保存.
2. 如果数据包之前已经收到, 就立即返回ACK并丢弃数据包.
3. 确定此数据包属于哪一个socket.
4. 将数据包保存到对应socket的接收队列.
5. 唤醒等待接收此socket数据的进程.

### 常见网络编程接口的实现

1. socket

2. bind

3. connect

4. listen

   listen 使一个套接字从默认的主动套接字转为被动套接字, 即可以响应外来连接, 当客户端对其调用 connect,
   被动套接字会自动与客户端进行三次握手. 内核为一个监听套接字维护两个队列:

   - 未完成连接队列(incomplete connection queue), 当第一个SYN数据包到达, 还未完成三次握手时,
     客户端对应的数据保存在此队列中.
   - 已完成连接队列(completed connection queue), 完成三次握手后(即收到客户端的ACK),
     会将客户端对应的数据转移到此队列.

   linux 2.2 之前, listen 函数的第二个参数(backlog)指定的是未完成队列的最大长度, 从 2.2 开始则指定了已完成队列的长度。而未完成队列的长度可用通过 */proc/sys/net/ipv4/tcp_max_syn_backlog* 来设置.

   可能出现这样的问题: 客户端发送了第一个SYN之后就当机了, 因此无法发送最后一个ACK, 此时该客户端对应的数据结构会永远保存在未完成队列中. 因此规定了一个数据在未完成队列中的最长时间, 超过此时间就会被移除.

5. accept

   从已完成队列的头部获取一个连接.

6. write/send

7. read/recv





# 分布式系统知识点

## 2PC

全称二阶段提交(two phase commit), 用于实现分布式事务的原子性. 即对于一个操作, 保证所有节点要么都执行, 要么都不执行.

由于不同节点不能直接获取其他节点的操作执行情况, 因此算法引入一个**协调者**(coordinator), 执行操作的节点称为**参与者**.
由参与者向协调者通知其操作的执行结果, 协调者根据结果通知所有参与者中止/提交操作.

算法分为两个阶段: 准备(Prepare)阶段和提交(Commit)阶段, 又称为投票阶段和执行阶段.

1. 准备阶段

   协调者给每个参与者发送 prepare 消息, 通知参与者执行操作. 参与者要么返回失败(例如权限验证失败),
   要么写本地的 redo 和 undo 日志, 并执行此操作, 但是不提交, 然后返回成功的消息.

2. 提交阶段

   协调者发送完 prepare 消息后, 就进入本阶段, 等待参与者的回复.
   如果所有参与者都回复成功, 那么协调者再向每个参与者发送 commit 消息, 通知其 commit 此操作.
   否则, 向所有参与者发送 rollback 消息, 通知其回滚此操作. 参与者的回复超时也会导致此结果.
   参与者收到 commit 消息后, 就会将操作提交, 并释放操作执行期间占用的资源.
   如果参与者收到 rollback 消息, 则会利用 undo 日志回滚操作, 并释放占用的资源.
   完成提交/回滚操作后, 参与者向协调者返回 ack 消息. 协调者收到所有参与者的 ack 后, 事务完成.

2PC 原理简单, 容易实现, 但是存在几个问题:

- 同步阻塞: 执行过程中参与者占据着公共资源, 其他需要使用资源的操作将会被阻塞.
- 单点问题: 协调者如果出现故障, 事务将无法完成. 可以采用多个备份协调者来处理此问题,
  但是在新的协调者启动前事务无法向前推进.
- 数据不一致: 在提交阶段, 协调者发送 commit 消息后故障, 并且只有部分参与者收到 commit 消息,
  这就导致了参与者的数据不一致. 并且, 如果只有一个参与者收到 commit 消息, 并且随后此节点也故障停机,
  后面即使新的协调者产生, 也无法确定整个系统的状态.

各个阶段可能出现的错误(这里只考虑fail-stop)及对应的解决方案.

## 3PC

3PC 在 2PC 的基础上, 加入了一个阶段用于检查各个参与者是否可以执行事务, 此阶段并不会执行事务.
三个阶段分别是 canCommit, preCommit, doCommit.
此外, 还在协调者和参与者中引入超时机制, 以应对 2PC 中 commit 消息丢失导致的不一致问题.
但是 3PC 仍然无法保证完全一致.

1. canCommit
   1. **协调者**向参与者发送 canCommit 消息, 等待(waiting state)参与者回复.
   2. **参与者**收到 canCommit 消息后, 如果认为可以执行事务, 返回 Yes, 进入 Prepared 状态,
      等待 preCommit 消息. 如果否则返回 No, 终止事务.
2. preCommit
   1. **协调者**在规定时间内收到所有参与者的 Yes 消息后, 向每个参与者发送 preCommit 消息,
      进入 Prepared 状态.
      否则, 即如果收到 No 消息或出现超时, 就中止事务, 向参与者发送 abort 消息.
   2. **参与者**如果在规定时间内收到 preCommit 消息, 就可以记录 redo 和 undo 日志,
      并执行对应操作, 然后返回 ack 消息给协调者, 等待 doCommit 消息.
      如果是 abort 消息, 则中止事务.
      如果 Prepared 状态超时, 即没有在规定时间收到 preCommit 消息, 参与者同样中止事务.
3. doCommit
   1. **协调者**如果在规定时间内收到(所有/大多数)参与者的 ack 消息, 就表明可以 commit 事务.
      协调者此时向每个参与者发送 doCommit 消息, 并转移到 commit state.
      否则, 向每个参与者发送 abort 消息.
   2. **参与者**如果在规定的时间收到 doCommit/abort 消息, 就 commit/abort 事务, 并返回 ack.
      如果超时, 同样 commit 事务.

在 doCommit 阶段参与者的超时机制基于这样的想法: 此时节点进行到 doCommit 阶段,
那么事务可以 commit 的概率是很大的, 因此没有收到 commit 消息时仍然执行 commit.

3PC 仍然存在问题, 例如, 当发送 preCommit 后, 只有部分参与者收到, 而此时协调者停机.
此时收到 preCommit 消息的节点会在超时后 commit 事务, 而其他参与者则会 abort 事务, 发生了不一致.

## CAP

CAP 理论指的是在 Consistency, Availability, Partion 三者中只能满足 CP 或 AP.

- Consistency: 指的是强一致性. 后面的读一定能读到前面写的内容, 所有读写都满足 linearizability.
- Availability: 任何非失败节点都应该在有限时间内响应请求.
- Partion: 允许节点之间丢失任意的消息, 当发生分区时, 不同分区间可能无法通信.

由于分布式系统中无法避免消息丢失, 分区等错误, 因此无法同时满足 CAP. 设想这样的情况:
集群发生分区(A, B), 用户向 A 请求读某个数据, 此时 A 不能确定是否有用户通过 B 更新了该数据.
因此, 如果返回数据, 就不能保证满足一致性(C), 如果不返回数据, 就不能满足可用性(A).

## BASE

BASE 是指基本可用(Basically Available), 软状态(Soft state), 最终一致性(Eventual consistency).
是对 CAP 的延伸, 核心思想是即使无法做到强一致性(CAP 中的 C), 但可以实现最终一致性.

- 基本可用: 系统出现故障时, 不会完全不可用, 核心功能仍然可用. 但是整体性能可能会下降, 功能不完整.
- 软状态: 系统在中间状态, 此时系统中不同副本间的状态可能会不一致, 但是不会应该整体可用性.
- 最终一致性: 软状态的持续时间是有限制的, 要保证能系统最终能达到一致状态.

最终一致性分为5种, 可以根据实际情况选择. BASE 的思想就是牺牲强一致性来保证可用性.





# 网络编程基础

## 常见问题

### Socket API

1. 网络编程一般步骤？

   - TCP：

     - 服务端：socket -> bind -> listen -> accept -> recv/send -> close。

     - 客户端：socket -> connect -> send/recv -> close。

   - UDP：

     - 服务端：socket -> bind -> recvfrom/sendto -> close。

     - 客户端：socket -> sendto/recvfrom -> close。

2. send、sendto区别，recv、recvfrom区别？


### TCP/UDP

1. TCP和UDP区别？

   - TCP面向连接（三次握手），通信前需要先建立连接；UDP面向无连接，通信前不需要连接。

   - TCP通过序号、重传、流量控制、拥塞控制实现可靠传输；UDP不保障可靠传输，尽最大努力交付。

   - TCP面向字节流传输，因此可以被分割并在接收端重组；UDP面向数据报传输。

2. TCP为什么不是两次握手而是三次？

   - 如果仅两次连接可能出现一种情况：客户端发送完连接报文（第一次握手）后由于网络不好，延时很久后报文到达服务端，服务端接收到报文后向客户端发起连接（第二次握手）。此时客户端会认定此报文为失效报文，但在两次握手情况下服务端会认为已经建立起了连接，服务端会一直等待客户端发送数据，但因为客户端会认为服务端第二次握手的回复是对失效请求的回复，不会去处理。这就造成了服务端一直等待客户端数据的情况，浪费资源。

3. TCP为什么挥手是四次而不是三次？

   - TCP是全双工的，它允许两个方向的数据传输被独立关闭。当主动发起关闭的一方关闭连接之后，TCP进入半关闭状态，此时主动方可以只关闭输出流。

   - 之所以不是三次而是四次主要是因为被动关闭方将"对主动关闭报文的确认"和"关闭连接"两个操作分两次进行。

   - "对主动关闭报文的确认"是为了快速告知主动关闭方，此关闭连接报文已经收到。此时被动方不立即关闭连接是为了将缓冲中剩下的数据从输出流发回主动关闭方（主动方接收到数据后同样要进行确认），因此要把"确认关闭"和"关闭连接"分两次进行。

   - **Linux的close实际上是同时关闭输入流和输出流，并不是我们常说的四次握手。半关闭函数为shutdown，它可以用来断开某个具体描述符的TCP输入流或输出流。**

4. 为什么要有TIME_WAIT状态，TIME_WAIT状态过多怎么解决？

   - 主动关闭连接一方在发送对被动关闭方关闭连接的确认报文时，有可能因为网络状况不佳，被动关闭方超时未能收到此报文而重发断开连接（FIN）报文，此时如果主动方不等待而是直接进入CLOSED状态，则接收到被动关闭方重发的断开连接的报文会触发RST分组而非ACK分组，当被动关闭一方接收到RST后会认为出错了。所以说处于TIME_WAIT状态就是为了在重新收到断开连接分组情况下进行确认。

   - 解决方法：

     - 可以通过修改sysctl中TIME_WAIT时间来减少此情况（HTTP 1.1也可以减少此状态）。

     - 利用SO_LINGER选项的强制关闭方式，发RST而不是FIN，来越过TIMEWAIT状态，直接进入CLOSED状态。

5. TCP建立连接及断开连接是状态转换？

   - 客户端：SYN_SENT -> ESTABLISHED -> FIN_WAIT_1 -> FIN_WAIT_2 -> TIME_WAIT。

   - 服务端：LISTEN -> SYN_RCVD -> ESTABLISHED -> CLOSE_WAIT -> LAST_ACK -> CLOSED。

6. TCP流量控制和拥塞控制的实现？

   - 流量控制：TCP采用大小可变的滑动窗口进行流量控制。窗口大小的单位是字节，在TCP报文段首部的窗口字段写入的数值就是当前给对方设置的发送窗口数值的上限，发送窗口在连接建立时由双方商定。但在通信的过程中，接收端可根据自己的资源情况，随时动态地调整对方的发送窗口上限值。

   - 拥塞控制：网络拥塞现象是指到达通信子网中某一部分的分组数量过多，使得该部分网络来不及处理，以致引起这部分乃至整个网络性能下降的现象。严重时甚至会导致网络通信业务陷入停顿，即出现死锁现象。拥塞控制是处理网络拥塞现象的一种机制。

7. TCP重传机制？

   - 滑动窗口机制，确立收发的边界，能让发送方知道已经发送了多少、尚未确认的字节数、尚待发送的字节数；让接收方知道已经确认收到的字节数。

   - 选择重传，用于对传输出错的序列进行重传。

8. 三次握手过程？

   - 主动建立连接方A的TCP向主机B发出连接请求报文段，其首部中的SYN(同步)标志位应置为1，表示想与目标主机B进行通信，并发送一个同步序列号x进行同步，表明在后面传送数据时的第一个数据字节的序号是x + 1。SYN同步报文会指明客户端使用的端口以及TCP连接的初始序号。

   - 接收连接方B的TCP收到连接请求报文段后，如同意则发回确认。在确认报中应将ACK位和SYN位置1，表示客户端的请求被接受。确认号应为x + 1，同时也为自己选择一个序号y。

   - 主动方A的TCP收到目标主机B的确认后要向目标主机B给出确认，其ACK置1，确认号为y + 1，而自己的序号为x + 1。

9. 四次挥手过程？

   - 主动关闭主机A的应用进程先向其TCP发出连接释放请求，并且不再发送数据。TCP通知对方要释放从A到B这个方向的连接，将发往主机B的TCP报文段首部的终止比特FIN置1，其序号x等于前面已传送过的数据的最后一个字节的序号加1。

   - 被动关闭主机B的TCP收到释放连接通知后即发出确认，其序号为y，确认号为x + 1，同时通知高层应用进程，这样，从A到B的连接就释放了，连接处于半关闭状态。但若主机B还有一些数据要发送主机A，则可以继续发送。主机A只要正确收到数据，仍应向主机B发送确认。

   - 若主机B不再向主机A发送数据，其应用进程就通知TCP释放连接。主机B发出的连接释放报文段必须将终止比特FIN和确认比特ACK置1，并使其序号仍为y，但还必须重复上次已发送过的ACK = x + 1。

   - 主机A必须对此发出确认，将ACK置1，ACK = y + 1，而自己的序号是x + 1。这样才把从B到A的反方向的连接释放掉。主机A的TCP再向其应用进程报告，整个连接已经全部释放。

### I/O模型

1. 阻塞和非阻塞I/O区别？

   - 如果内核缓冲没有数据可读时，read()系统调用会一直等待有数据到来后才从阻塞态中返回，这就是阻塞I/O。

   - 非阻塞I/O在遇到上述情况时会立即返回给用户态进程一个返回值，并设置errno为EAGAIN。

   - 对于往缓冲区写的操作同理。

2. 同步和异步区别？

   - 同步I/O指处理I/O操作的进程和处理I/O操作的进程是同一个。

   - 异步I/O中I/O操作由操作系统完成，并不由产生I/O的用户进程执行。

3. Reactor和Proactor区别？

   - Reactor模式已经是同步I/O，处理I/O操作的依旧是产生I/O的程序；Proactor是异步I/O，产生I/O调用的用户进程不会等待I/O发生，具体I/O操作由操作系统完成。

   - 异步I/O需要操作系统支持，Linux异步I/O为AIO，Windows为IOCP。

4. epoll和select及poll区别？

   - 文件描述符数量限制：select文件描述符数量受到限制，最大为2048（FD_SETSIZE），可重编内核修改但治标不治本；poll没有最大文件描述符数量限制；epoll没有最大文件描述符数量限制。

   - 检查机制：select和poll会以遍历方式（轮询机制）检查每一个文件描述符以确定是否有I/O就绪，每次执行时间会随着连接数量的增加而线性增长；epoll则每次返回后只对活跃的文件描述符队列进行操作（每个描述符都通过回调函数实现，只有活跃的描述符会调用回调函数并添加至队列中）。**当大量连接是非活跃连接时epoll相对于select和poll优势比较大，若大多为活跃连接则效率未必高（设计队列维护及红黑树创建）**

   - 数据传递方式：select和poll需要将FD_SET在内核空间和用户空间来回拷贝；epoll则避免了不必要的数据拷贝。

5. epoll中ET和LT模式的区别与实现原理？

   - LT：默认工作方式，同时支持阻塞I/O和非阻塞I/O，LT模式下，内核告知某一文件描述符读、写是否就绪了，然后你可以对这个就绪的文件描述符进行I/O操作。如果不作任何操作，内核还是会继续通知。这种模式编程出错误可能性较小但由于重复提醒，效率相对较低。传统的select、poll都是这种模型的代表。

   - ET：高速工作方式（因为减少了epoll_wait触发次数），适合高并发，只支持非阻塞I/O，ET模式下，内核告知某一文件描述符读、写是否就绪了，然后他假设已经知道该文件描述符是否已经就绪，内核不会再为这个文件描述符发更多的就绪通知（epoll_wait不会返回），直到某些操作导致文件描述符状态不再就绪。

6. ET模式下要注意什么（如何使用ET模式）？

   - 对于读操作，如果read没有一次读完buff数据，下一次将得不到就绪通知（ET特性），造成buff中数据无法读出，除非有新数据到达。

     - 解决方法：将套接字设置为非阻塞，用while循环包住read，只要buff中有数据，就一直读。一直读到产生EAGIN错误。

   - 对于写操作主要因为ET模式下非阻塞需要我们考虑如何将用户要求写的数据写完。

     - 解决方法：只要buff还有空间且用户请求写的数据还未写完，就一直写。


### 操作系统

1. Linux下进程间通信方式？

   - 管道：

     - 无名管道（内存文件）：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程之间使用。进程的亲缘关系通常是指父子进程关系。

     - 有名管道（FIFO文件，借助文件系统）：有名管道也是半双工的通信方式，但是允许在没有亲缘关系的进程之间使用，管道是先进先出的通信方式。

   - 共享内存：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的IPC方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与信号量，配合使用来实现进程间的同步和通信。

   - 消息队列：消息队列是有消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。

   - 套接字：适用于不同机器间进程通信，在本地也可作为两个进程通信的方式。

   - 信号：用于通知接收进程某个事件已经发生，比如按下ctrl + C就是信号。

   - 信号量：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，实现进程、线程的对临界区的同步及互斥访问。

2. Linux下同步机制？

   - POSIX信号量：可用于进程同步，也可用于线程同步。

   - POSIX互斥锁 + 条件变量：只能用于线程同步。

3. 线程和进程的区别？

   - 调度：线程是调度的基本单位（PC，状态码，通用寄存器，线程栈及栈指针）；进程是拥有资源的基本单位（打开文件，堆，静态区，代码段等）。

   - 并发性：一个进程内多个线程可以并发（最好和CPU核数相等）；多个进程可以并发。

   - 拥有资源：线程不拥有系统资源，但一个进程的多个线程可以共享隶属进程的资源；进程是拥有资源的独立单位。

   - 系统开销：线程创建销毁只需要处理PC值，状态码，通用寄存器值，线程栈及栈指针即可；进程创建和销毁需要重新分配及销毁task_struct结构。

4. 介绍虚拟内存？

5. 内存分配及碎片管理？

6. 有很多小的碎片文件怎么处理？

## Linux

1. fork系统调用？

2. 什么场景用共享内存，什么场景用匿名管道？

3. 有没有用过开源的cgi框架？

4. epoll和select比有什么优势有什么劣势，epoll有什么局限性？

   - epoll优势：1. 没有描述符数量限制；2. 通过回调代替轮询；3. 内存映射代替数据在用户和内核空间来回拷贝。

   - epoll劣势（局限性）：select可以跨平台，epoll只能在Linux上使用。

5. 线程（POSIX）锁有哪些？

   - 互斥锁（mutex）

     - 互斥锁属于sleep-waiting类型的锁。例如在一个双核的机器上有两个线程A和B，它们分别运行在core 0和core 1上。假设线程A想要通过pthread_mutex_lock操作去得到一个临界区的锁，而此时这个锁正被线程B所持有，那么线程A就会被阻塞，此时会通过上下文切换将线程A置于等待队列中，此时core 0就可以运行其他的任务（如线程C）。

   - 条件变量(cond)

   - 自旋锁(spin)

     - 自旋锁属于busy-waiting类型的锁，如果线程A是使用pthread_spin_lock操作去请求锁，如果自旋锁已经被线程B所持有，那么线程A就会一直在core 0上进行忙等待并不停的进行锁请求，检查该自旋锁是否已经被线程B释放，直到得到这个锁为止。因为自旋锁不会引起调用者睡眠，所以自旋锁的效率远高于互斥锁。

     - 虽然它的效率比互斥锁高，但是它也有些不足之处：

       - 自旋锁一直占用CPU，在未获得锁的情况下，一直进行自旋，所以占用着CPU，如果不能在很短的时间内获得锁，无疑会使CPU效率降低。

       - 在用自旋锁时有可能造成死锁，当递归调用时有可能造成死锁。

     - 自旋锁只有在内核可抢占式或SMP的情况下才真正需要，在单CPU且不可抢占式的内核下，自旋锁的操作为空操作。自旋锁适用于锁使用者保持锁时间比较短的情况下。

   - 读写锁（rwlock）

## TKeed

1. 项目整体架构是什么？请求怎么进来？处理完怎么出去？

   - 整体架构为：I/O多路复用 + 非阻塞I/O + 线程池，即Reactor反应堆模型。

   - 处理流程：

     - 创建监听描述符并在epoll中注册。

     - 监听到新请求，epoll从阻塞中返回并建立新连接。

     - 将新建的连接描述符在epoll中注册。

     - 当某个连接接收到用户请求数据时，将任务投放到线程池任务队列中。

     - 工作线程被条件变量（任务队列不为空）唤醒，并互斥访问线程池。

     - 得到任务的线程完成解析及响应。

       - 工作线程执行函数为do_request，参数即为task结构。

         - 每个task结构在建立连接是被初始化，包含描述符、缓冲区等信息是，并在do_request执行时记录解析结果及状态。

2. 在做压测时，机器配置是什么样的？数据如何？

   - 本地测试。

     - 四核i5处理器 + 128G固态硬盘。

3. 为了QPS（Query per second, 1秒内完成的请求数量）更高可以做哪些改进？

   - 对请求结果做缓存。

   - 多次搜索请求采用异步I/O，改串行为并行。

   - 调整并发线程数量（通常和CPU核心数相同）。

4. 有没有注意到压测时内存，CPU，I/O指标？

   - 压测同时打开top -H -p pid查看CPU，I/O，内存信息。

5. 压测时有没有见过TIME_WAIT？怎么样会见到？怎么解决？

   - 当服务端关闭连接时会产生TIME_WAIT。

   - 解决方案：

     - HTTP 1.1在同一个TCP连接上尽

\9. epoll的实现知道么？在内核当中是什么样的数据结构进行存储，每个操作的时间复杂度是多少？

作者：特立独行MVP
链接：https://www.nowcoder.com/discuss/163281?form=sx21
来源：牛客网



\17. 你之前是做的什么项目？做过什么项目？ 

  \18. IO多路复用那部分你是怎么去抽象这个事情的？怎么去实现业务逻辑和核心逻辑的区分是怎么去组织这个代码？ 

  \19. 怎么保证你epoll的代码可以尽量的被复用呢？

作者：特立独行MVP
链接：https://www.nowcoder.com/discuss/163281?form=sx21
来源：牛客网



\10. epoll的原理你知道么？ 

  \11. epoll的边沿触发和水平触发这个了解么？说一下 

  \12. 你使用的是哪种模式呢？ 

  \13. 选择边沿触发，虽然只通知一次但是你应用层还是要把这个状态记录下来的，那么一个是应用层消耗一个是内核态消耗，有考虑过么？